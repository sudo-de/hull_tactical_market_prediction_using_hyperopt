# Architecture Overview

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HULL TACTICAL MARKET PREDICTION             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Input    â”‚
â”‚   train.csv     â”‚
â”‚   test.csv      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA PREPROCESSING LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  load_trainset() / load_testset()                      â”‚   â”‚
â”‚  â”‚  - Load CSV with Polars                                â”‚   â”‚
â”‚  â”‚  - Rename target columns                                â”‚   â”‚
â”‚  â”‚  - Type casting (Float64)                              â”‚   â”‚
â”‚  â”‚  - Basic cleaning                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FEATURE ENGINEERING LAYER                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  src/features.py                                        â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â€¢ create_lag_features()                                â”‚   â”‚
â”‚  â”‚    - Lags: [1, 2, 3, 5, 10 days]                        â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â€¢ create_rolling_features()                            â”‚   â”‚
â”‚  â”‚    - Mean/Std/Min/Max                                   â”‚   â”‚
â”‚  â”‚    - Windows: [5, 10, 20, 50]                          â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â€¢ create_momentum_features()                            â”‚   â”‚
â”‚  â”‚    - RSI-like indicators                                â”‚   â”‚
â”‚  â”‚    - Moving average deviations                          â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â€¢ create_interaction_features()                        â”‚   â”‚
â”‚  â”‚    - Ratios, products                                   â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â€¢ create_volatility_features()                         â”‚   â”‚
â”‚  â”‚    - Rolling volatility                                 â”‚   â”‚
â”‚  â”‚    - Coefficient of variation                           â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  Result: 88 features from 13 basic features             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEATURE SCALING LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  StandardScaler from sklearn                           â”‚   â”‚
â”‚  â”‚  - fit() on training data                               â”‚   â”‚
â”‚  â”‚  - transform() on train and test                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MODEL TRAINING LAYER                         â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  ElasticNet  â”‚  â”‚  LightGBM    â”‚  â”‚  XGBoost     â”‚         â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚         â”‚
â”‚  â”‚  src/models/ â”‚  â”‚  src/models/ â”‚  â”‚  src/models/ â”‚         â”‚
â”‚  â”‚  elastic_net.â”‚  â”‚  lightgbm_   â”‚  â”‚  xgboost_    â”‚         â”‚
â”‚  â”‚  py          â”‚  â”‚  model.py    â”‚  â”‚  model.py    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                  â”‚                  â”‚                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                            â–¼                                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                  â”‚   Ensemble Model    â”‚                          â”‚
â”‚                  â”‚   src/models/       â”‚                          â”‚
â”‚                  â”‚   ensemble.py       â”‚                          â”‚
â”‚                  â”‚                     â”‚                          â”‚
â”‚                  â”‚  â€¢ Voting Ensemble â”‚                          â”‚
â”‚                  â”‚  â€¢ Weighted Average â”‚                          â”‚
â”‚                  â”‚  â€¢ Stacking         â”‚                          â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   HYPERPARAMETER OPTIMIZATION                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Optuna (Bayesian Optimization)                        â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  â€¢ Time Series Cross-Validation (5 folds)                â”‚   â”‚
â”‚  â”‚  â€¢ N trials per model (default: 20)                     â”‚   â”‚
â”‚  â”‚  â€¢ Parallel execution support                            â”‚   â”‚
â”‚  â”‚  â€¢ Early stopping                                        â”‚   â”‚
â”‚  â”‚  â€¢ Best parameter selection                              â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  Search Spaces:                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚ ElasticNet   â”‚  â”‚  LightGBM    â”‚  â”‚  XGBoost    â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ alpha      â”‚  â”‚ â€¢ leaves     â”‚  â”‚ â€¢ depth     â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ l1_ratio   â”‚  â”‚ â€¢ lr         â”‚  â”‚ â€¢ lr        â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ features   â”‚  â”‚ â€¢ subsample â”‚     â”‚   â”‚
â”‚  â”‚                    â”‚ â€¢ bagging    â”‚  â”‚ â€¢ gamma     â”‚     â”‚   â”‚
â”‚  â”‚                    â”‚ â€¢ lambda     â”‚  â”‚ â€¢ lambda    â”‚     â”‚   â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL EVALUATION LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  compare_models.py                                     â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â€¢ calculate_metrics()                                 â”‚   â”‚
â”‚  â”‚    - RMSE (Root Mean Squared Error)                    â”‚   â”‚
â”‚  â”‚    - MAE (Mean Absolute Error)                         â”‚   â”‚
â”‚  â”‚    - RÂ² Score                                           â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â€¢ plot_predictions()                                   â”‚   â”‚
â”‚  â”‚    - Visualization of predictions                      â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â€¢ plot_feature_importance()                            â”‚   â”‚
â”‚  â”‚    - Top N features visualization                      â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â€¢ evaluate_model()                                    â”‚   â”‚
â”‚  â”‚    - Signal conversion                                 â”‚   â”‚
â”‚  â”‚    - Range validation                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PREDICTION & OUTPUT                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  convert_ret_to_signal()                               â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â€¢ Input: Raw predictions (returns)                   â”‚   â”‚
â”‚  â”‚  â€¢ Process:                                             â”‚   â”‚
â”‚  â”‚    - Multiply by SIGNAL_MULTIPLIER (400)               â”‚   â”‚
â”‚  â”‚    - Add 1.0                                            â”‚   â”‚
â”‚  â”‚    - Clip to [0.0, 2.0] range                          â”‚   â”‚
â”‚  â”‚  â€¢ Output: Trading signals                             â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â€¢ Competition scoring:                                 â”‚   â”‚
â”‚  â”‚    - evaluation.py                                      â”‚   â”‚
â”‚  â”‚    - Volatility-adjusted Sharpe ratio                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data    â”‚
â”‚  CSV Files   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing                          â”‚
â”‚  â€¢ Load CSV                              â”‚
â”‚  â€¢ Type conversion                       â”‚
â”‚  â€¢ Basic cleaning                        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Engineering                    â”‚
â”‚  â€¢ 13 â†’ 88 features                      â”‚
â”‚  â€¢ Lags, rolling stats                  â”‚
â”‚  â€¢ Momentum, interactions              â”‚
â”‚  â€¢ Volatility metrics                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scaling                                â”‚
â”‚  â€¢ StandardScaler                       â”‚
â”‚  â€¢ Fit on train, transform both         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Optuna Optimization                    â”‚
â”‚  â€¢ Bayesian search                       â”‚
â”‚  â€¢ Cross-validation                      â”‚
â”‚  â€¢ Best params selected                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Training                          â”‚
â”‚  â€¢ ElasticNet                            â”‚
â”‚  â€¢ LightGBM âœ… Best                      â”‚
â”‚  â€¢ XGBoost                               â”‚
â”‚  â€¢ Ensemble                              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Predictions                            â”‚
â”‚  â€¢ Raw returns                           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Signal Conversion                      â”‚
â”‚  â€¢ ret * 400 + 1                         â”‚
â”‚  â€¢ Clip [0, 2]                           â”‚
â”‚  â€¢ Trading signals                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Model Architecture Details

### 1. ElasticNet Model
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ElasticNet Architecture         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Algorithm: Regularized Regression      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                         â”‚
â”‚  Input: X (88 features)                 â”‚
â”‚         â””â”€â–º StandardScaler             â”‚
â”‚         â””â”€â–º Linear Model               â”‚
â”‚                                         â”‚
â”‚  Regularization:                        â”‚
â”‚  â€¢ L1 (Lasso): Alpha Ã— L1_ratio        â”‚
â”‚  â€¢ L2 (Ridge): Alpha Ã— (1 - L1_ratio)  â”‚
â”‚                                         â”‚
â”‚  Hyperparameters (Optuna):             â”‚
â”‚  â€¢ alpha: [1e-4, 1.0] (log scale)     â”‚
â”‚  â€¢ l1_ratio: [0.0, 1.0]                â”‚
â”‚                                         â”‚
â”‚  Best Score: 0.010908 RMSE             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. LightGBM Model (Best Performer)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       LightGBM Architecture             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Algorithm: Gradient Boosting (Tree)   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                         â”‚
â”‚  Input: X (88 features)                 â”‚
â”‚         â””â”€â–º Decision Trees              â”‚
â”‚         â””â”€â–º Leaf-wise growth            â”‚
â”‚         â””â”€â–º Ensemble of trees          â”‚
â”‚                                         â”‚
â”‚  Hyperparameters (Optuna):             â”‚
â”‚  â€¢ num_leaves: [10, 300]               â”‚
â”‚  â€¢ learning_rate: [0.01, 0.3]          â”‚
â”‚  â€¢ feature_fraction: [0.4, 1.0]        â”‚
â”‚  â€¢ bagging_fraction: [0.4, 1.0]        â”‚
â”‚  â€¢ min_child_samples: [5, 100]         â”‚
â”‚  â€¢ reg_alpha: [1e-8, 10]               â”‚
â”‚  â€¢ reg_lambda: [1e-8, 10]              â”‚
â”‚                                         â”‚
â”‚  Best Score: 0.009635 RMSE ğŸ†          â”‚
â”‚  Best Params:                          â”‚
â”‚    â€¢ num_leaves: 290                   â”‚
â”‚    â€¢ lr: 0.069                         â”‚
â”‚    â€¢ feature_fraction: 0.695            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. XGBoost Model
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         XGBoost Architecture            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Algorithm: Extreme Gradient Boosting  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                         â”‚
â”‚  Input: X (88 features)                 â”‚
â”‚         â””â”€â–º Level-wise trees            â”‚
â”‚         â””â”€â–º Regularization              â”‚
â”‚         â””â”€â–º Handling missing values     â”‚
â”‚                                         â”‚
â”‚  Hyperparameters (Optuna):             â”‚
â”‚  â€¢ max_depth: [3, 10]                   â”‚
â”‚  â€¢ learning_rate: [0.01, 0.3]           â”‚
â”‚  â€¢ subsample: [0.4, 1.0]                â”‚
â”‚  â€¢ colsample_bytree: [0.4, 1.0]        â”‚
â”‚  â€¢ min_child_weight: [1, 10]           â”‚
â”‚  â€¢ gamma: [1e-8, 10]                   â”‚
â”‚  â€¢ reg_alpha: [1e-8, 10]               â”‚
â”‚  â€¢ reg_lambda: [1e-8, 10]              â”‚
â”‚                                         â”‚
â”‚  Best Score: 0.009800 RMSE             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Ensemble Model
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Ensemble Architecture             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Type: Weighted Voting                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                         â”‚
â”‚  Input: Individual model predictions   â”‚
â”‚                                         â”‚
â”‚  Models & Weights:                     â”‚
â”‚  â€¢ ElasticNet: 30% weight              â”‚
â”‚  â€¢ LightGBM: 35% weight                â”‚
â”‚  â€¢ XGBoost: 35% weight                 â”‚
â”‚                                         â”‚
â”‚  Output:                               â”‚
â”‚  Î£ (prediction_i Ã— weight_i)            â”‚
â”‚                                         â”‚
â”‚  Benefits:                             â”‚
â”‚  â€¢ Reduces overfitting                  â”‚
â”‚  â€¢ Better generalization                â”‚
â”‚  â€¢ Robust to individual model failures  â”‚
â”‚                                         â”‚
â”‚  Signal Range: [0.55, 2.00]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Feature Engineering Pipeline

```
Input: 13 Base Features
â”‚
â”œâ”€â–º Lag Features (Ã—5 lags each)
â”‚   â€¢ S2_lag_1, S2_lag_2, ..., I2_lag_5
â”‚   â‰ˆ +25 features
â”‚
â”œâ”€â–º Rolling Statistics (Ã—4 stats Ã—3 windows)
â”‚   â€¢ mean_5, std_5, min_5, max_5
â”‚   â€¢ mean_10, std_10, min_10, max_10
â”‚   â€¢ mean_20, std_20, min_20, max_20
â”‚   â‰ˆ +48 features
â”‚
â”œâ”€â–º Momentum Indicators
â”‚   â€¢ RSI-like positive/negative changes
â”‚   â€¢ Moving average deviations
â”‚   â‰ˆ +15 features
â”‚
â””â”€â–º Interaction Features
    â€¢ Ratios (I2/I1, M11/avg)
    â€¢ Volatility features
    â‰ˆ +10 features
    â”‚
    â–¼
Output: 88 Engineered Features
```

## Training Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Script (train.py)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  1. Load Data                                â”‚
â”‚     â”œâ”€â–º train.csv                           â”‚
â”‚     â””â”€â–º test.csv                            â”‚
â”‚                                              â”‚
â”‚  2. Feature Engineering                      â”‚
â”‚     â”œâ”€â–º create_advanced_features()           â”‚
â”‚     â””â”€â–º select_features()                   â”‚
â”‚                                              â”‚
â”‚  3. Scale Features                           â”‚
â”‚     â””â”€â–º StandardScaler.fit()               â”‚
â”‚                                              â”‚
â”‚  4. Train Models (with Optuna)               â”‚
â”‚     â”œâ”€â–º ElasticNet.fit()                    â”‚
â”‚     â”œâ”€â–º LightGBM.fit()                      â”‚
â”‚     â”œâ”€â–º XGBoost.fit()                       â”‚
â”‚     â””â”€â–º Ensemble.fit()                      â”‚
â”‚                                              â”‚
â”‚  5. Generate Predictions                     â”‚
â”‚     â”œâ”€â–º model.predict(X_test)               â”‚
â”‚     â””â”€â–º convert_ret_to_signal()            â”‚
â”‚                                              â”‚
â”‚  6. Evaluation                               â”‚
â”‚     â”œâ”€â–º Calculate metrics                   â”‚
â”‚     â”œâ”€â–º Feature importance                  â”‚
â”‚     â””â”€â–º Signal validation                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## File Organization

```
hull_tactical_market_prediction_using_hyperopt/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features.py              # Feature engineering
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ elastic_net.py       # ElasticNet model
â”‚   â”‚   â”œâ”€â”€ lightgbm_model.py   # LightGBM model
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py    # XGBoost model
â”‚   â”‚   â””â”€â”€ ensemble.py          # Ensemble methods
â”‚   â”œâ”€â”€ config.py                # Configuration
â”‚   â””â”€â”€ data.py                  # Data loading
â”‚
â”œâ”€â”€ input/
â”‚   â””â”€â”€ hull-tactical-market-prediction/
â”‚       â”œâ”€â”€ train.csv            # Training data
â”‚       â”œâ”€â”€ test.csv             # Test data
â”‚       â””â”€â”€ kaggle_evaluation/   # Eval framework
â”‚
â”œâ”€â”€ train.py                     # Main training script
â”œâ”€â”€ main.py                       # Basic implementation
â”œâ”€â”€ compare_models.py            # Model comparison
â”œâ”€â”€ evaluation.py                # Scoring function
â”œâ”€â”€ requirements.txt             # Dependencies
â”‚
â”œâ”€â”€ Documentation/
â”‚   â”œâ”€â”€ README.md                # Project overview
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # This file
â”‚   â”œâ”€â”€ TRAINING_RESULTS.md      # Results summary
â”‚   â”œâ”€â”€ QUICK_START.md          # Quick guide
â”‚   â”œâ”€â”€ ADVANCED_FEATURES.md    # Feature docs
â”‚   â””â”€â”€ IMPLEMENTATION_SUMMARY.md
â”‚
â””â”€â”€ artifacts/                   # Outputs
    â”œâ”€â”€ predictions_comparison.png
    â”œâ”€â”€ feature_importance.png
    â””â”€â”€ evaluation_report.txt
```

## Performance Characteristics

### Model Comparison Table

| Model | CV Score | Training Time | Parameters | Strengths |
|-------|----------|---------------|------------|-----------|
| **LightGBM** | 0.009635 | ~30s | 8 | Fast, accurate, great for many features |
| XGBoost | 0.009800 | ~45s | 9 | Robust, handles missing values well |
| Ensemble | Combined | ~120s | All | Most stable, best generalization |
| ElasticNet | 0.010908 | ~5s | 2 | Interpretable, fast, linear baseline |

### Feature Engineering Impact

```
Before: 13 basic features
         â†“
After:  88 engineered features
         â†‘
    6.8x more features

Improvement:
â€¢ Captures temporal patterns (lags)
â€¢ Identifies trends (rolling stats)
â€¢ Detects momentum (RSI-like)
â€¢ Models interactions (ratios)
â€¢ Measures volatility (std, CV)
```

## Key Design Decisions

1. **Feature Engineering**: Aggressive feature creation to capture market dynamics
2. **Multiple Algorithms**: Different models capture different patterns
3. **Optuna Optimization**: Bayesian optimization vs grid search for efficiency
4. **Time Series CV**: Respects temporal order for realistic evaluation
5. **Ensemble Approach**: Combines strengths of all models for robustness
6. **Signal Conversion**: Clips to [0, 2] range for competition compliance

## Technology Stack

- **Data Processing**: Polars (fast dataframe operations)
- **ML Models**: scikit-learn, LightGBM, XGBoost
- **Optimization**: Optuna (Bayesian optimization)
- **Evaluation**: scikit-learn metrics
- **Visualization**: Matplotlib, Seaborn
- **Language**: Python 3.13

## Scalability Considerations

- **Feature Engineering**: O(n) where n = number of features
- **Model Training**: O(n Ã— m Ã— trials) where n=samples, m=features
- **Predictions**: O(1) per prediction
- **Memory**: ~2GB RAM for full training
- **Parallel**: Optuna can use multiple cores

## Extensibility

The architecture supports:
- Adding new models via `src/models/`
- New features via `src/features.py`
- Custom evaluation metrics
- Additional ensemble strategies
- Different optimization algorithms

