{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a876171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import polars as pl \n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241fb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/test.csv\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/train.csv\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__pycache__/kaggle_evaluation_pb2.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__pycache__/kaggle_evaluation_pb2_grpc.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__pycache__/__init__.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/__pycache__/templates.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/__pycache__/relay.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/__pycache__/base_gateway.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/core/__pycache__/__init__.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/__pycache__/default_inference_server.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/__pycache__/default_gateway.cpython-313.pyc\n",
      "/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/kaggle_evaluation/__pycache__/__init__.cpython-313.pyc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c55005",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1e7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ PATHS ============\n",
    "DATA_PATH: Path = Path('/Users/sudip/hull_tactical_market_prediction_using_hyperopt/input/hull-tactical-market-prediction/')\n",
    "\n",
    "# ============ RETURNS TO SIGNAL CONFIGS ============\n",
    "MIN_SIGNAL: float = 0.0                         # Minimum value for the daily signal \n",
    "MAX_SIGNAL: float = 2.0                         # Maximum value for the daily signal \n",
    "SIGNAL_MULTIPLIER: float = 400.0                # Multiplier of the OLS market forward excess returns predictions to signal \n",
    "\n",
    "# ============ MODEL CONFIGS ============\n",
    "CV: int = 10                                    # Number of cross validation folds in the model fitting\n",
    "L1_RATIO: float = 0.5                           # ElasticNet mixing parameter\n",
    "ALPHAS: np.ndarray = np.logspace(-4, 2, 100)    # Constant that multiplies the penalty terms\n",
    "MAX_ITER: int = 1000000  \n",
    "\n",
    "# # Print results\n",
    "# print(\"DATA_PATH:\", DATA_PATH)\n",
    "# print(\"MIN_SIGNAL:\", MIN_SIGNAL)\n",
    "# print(\"MAX_SIGNAL:\", MAX_SIGNAL)\n",
    "# print(\"SIGNAL_MULTIPLIER:\", SIGNAL_MULTIPLIER)\n",
    "# print(\"CV:\", CV)\n",
    "# print(\"L1_RATIO:\", L1_RATIO)\n",
    "# print(\"ALPHAS:\", ALPHAS)\n",
    "# print(\"MAX_ITER:\", MAX_ITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471d5a4",
   "metadata": {},
   "source": [
    "## Dataclasses Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbb273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Output\n",
    "@dataclass\n",
    "class DatasetOutput:\n",
    "    X_train : pl.DataFrame \n",
    "    X_test: pl.DataFrame\n",
    "    y_train: pl.Series\n",
    "    y_test: pl.Series\n",
    "    scaler: StandardScaler\n",
    "\n",
    "# ElasticNet Parameters\n",
    "@dataclass \n",
    "class ElasticNetParameters:\n",
    "    l1_ratio : float \n",
    "    cv: int\n",
    "    alphas: np.ndarray \n",
    "    max_iter: int \n",
    "    \n",
    "    def __post_init__(self): \n",
    "        if self.l1_ratio < 0 or self.l1_ratio > 1: \n",
    "            raise ValueError(\"Wrong initializing value for ElasticNet l1_ratio\")\n",
    "\n",
    "# Ret to Signal Parameters\n",
    "@dataclass(frozen=True)\n",
    "class RetToSignalParameters:\n",
    "    signal_multiplier: float \n",
    "    min_signal : float = MIN_SIGNAL\n",
    "    max_signal : float = MAX_SIGNAL\n",
    "\n",
    "# Print results\n",
    "elastic_params = ElasticNetParameters(\n",
    "    l1_ratio=0.5,\n",
    "    cv=10,\n",
    "    alphas=np.logspace(-4, 2, 100),\n",
    "    max_iter=1_000_000\n",
    ")\n",
    "\n",
    "signal_params = RetToSignalParameters(signal_multiplier=400.0)\n",
    "\n",
    "# print(elastic_params)\n",
    "# print(signal_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c9093",
   "metadata": {},
   "source": [
    "## Set the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98f7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ret to Signal Parameters\n",
    "ret_signal_params = RetToSignalParameters(\n",
    "    signal_multiplier= SIGNAL_MULTIPLIER\n",
    ")\n",
    "\n",
    "enet_params = ElasticNetParameters(\n",
    "    l1_ratio = L1_RATIO, \n",
    "    cv = CV, \n",
    "    alphas = ALPHAS, \n",
    "    max_iter = MAX_ITER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd5a3d",
   "metadata": {},
   "source": [
    "## Dataset Loading/Creating Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1041307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainset() -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The preprocessed training DataFrame.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pl.read_csv(DATA_PATH / \"train.csv\")\n",
    "        .rename({'market_forward_excess_returns':'target'})\n",
    "        .with_columns(\n",
    "            pl.exclude('date_id').cast(pl.Float64, strict=False)\n",
    "        )\n",
    "        .head(-10)\n",
    "    )\n",
    "\n",
    "def load_testset() -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the testing dataset.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The preprocessed testing DataFrame.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pl.read_csv(DATA_PATH / \"test.csv\")\n",
    "        .rename({'lagged_forward_returns':'target'})\n",
    "        .with_columns(\n",
    "            pl.exclude('date_id').cast(pl.Float64, strict=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def create_example_dataset(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates new features and cleans a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input Polars DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The DataFrame with new features, selected columns, and no null values.\n",
    "    \"\"\"\n",
    "    vars_to_keep: List[str] = [\n",
    "        # D Columns\n",
    "        \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\",\n",
    "        # E Columns\n",
    "        \"E1\", \"E2\", \"E3\", \"E4\", \"E5\", \"E6\", \"E7\", \"E8\", \"E9\", \"E10\", \"E11\", \"E12\",\n",
    "        \"E13\", \"E14\", \"E15\", \"E16\", \"E17\", \"E18\", \"E19\", \"E20\",\n",
    "        # I Columns\n",
    "        \"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\", \"I8\", \"I9\",\n",
    "        # M Columns\n",
    "        \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"M10\", \"M11\", \"M12\",\n",
    "        \"M13\", \"M14\", \"M15\", \"M16\", \"M17\", \"M18\",\n",
    "        # P Columns\n",
    "        \"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10\", \"P11\", \"P12\", \"P13\",\n",
    "        # S Columns\n",
    "        \"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"S10\", \"S11\", \"S12\",\n",
    "        # V Columns\n",
    "        \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"V10\", \"V11\", \"V12\", \"V13\",\n",
    "        # Derived features\n",
    "        \"U1\", \"U2\"\n",
    "    ]\n",
    "    \n",
    "    # Only keep columns that actually exist in the dataframe\n",
    "    available_cols = df.columns\n",
    "    vars_to_keep = [col for col in vars_to_keep if col in available_cols]\n",
    "\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            (pl.col(\"I2\") - pl.col(\"I1\")).alias(\"U1\"),\n",
    "            (pl.col(\"M11\") / ((pl.col(\"I2\") + pl.col(\"I9\") + pl.col(\"I7\")) / 3)).alias(\"U2\")\n",
    "        )\n",
    "        .select([\"date_id\", \"target\"] + vars_to_keep)\n",
    "        .with_columns([\n",
    "            pl.col(col).fill_null(pl.col(col).ewm_mean(com=0.5))\n",
    "            for col in vars_to_keep\n",
    "        ])\n",
    "        .drop_nulls()\n",
    "    )\n",
    "    \n",
    "def join_train_test_dataframes(train: pl.DataFrame, test: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins two dataframes by common columns and concatenates them vertically.\n",
    "\n",
    "    Args:\n",
    "        train (pl.DataFrame): The training DataFrame.\n",
    "        test (pl.DataFrame): The testing DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: A single DataFrame with vertically stacked data from common columns.\n",
    "    \"\"\"\n",
    "    common_columns: list[str] = [col for col in train.columns if col in test.columns]\n",
    "    \n",
    "    return pl.concat([train.select(common_columns), test.select(common_columns)], how=\"vertical\")\n",
    "\n",
    "def split_dataset(train: pl.DataFrame, test: pl.DataFrame, features: list[str]) -> DatasetOutput: \n",
    "    \"\"\"\n",
    "    Splits the data into features (X) and target (y), and scales the features.\n",
    "\n",
    "    Args:\n",
    "        train (pl.DataFrame): The processed training DataFrame.\n",
    "        test (pl.DataFrame): The processed testing DataFrame.\n",
    "        features (list[str]): List of features to used in model. \n",
    "\n",
    "    Returns:\n",
    "        DatasetOutput: A dataclass containing the scaled feature sets, target series, and the fitted scaler.\n",
    "    \"\"\"\n",
    "    X_train = train.select(features)\n",
    "    y_train = train.get_column('target')\n",
    "    X_test = test.select(features)\n",
    "    y_test = test.get_column('target')\n",
    "    \n",
    "    scaler = StandardScaler() \n",
    "    \n",
    "    X_train_scaled_np = scaler.fit_transform(X_train)\n",
    "    X_train = pl.from_numpy(X_train_scaled_np, schema=features)\n",
    "    \n",
    "    X_test_scaled_np = scaler.transform(X_test)\n",
    "    X_test = pl.from_numpy(X_test_scaled_np, schema=features)\n",
    "    \n",
    "    \n",
    "    return DatasetOutput(\n",
    "        X_train = X_train,\n",
    "        y_train = y_train, \n",
    "        X_test = X_test, \n",
    "        y_test = y_test,\n",
    "        scaler = scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226f29c",
   "metadata": {},
   "source": [
    "## Converting Return Prediction to Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46502759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ret_to_signal(\n",
    "    ret_arr: np.ndarray,\n",
    "    params: RetToSignalParameters\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts raw model predictions (expected returns) into a trading signal.\n",
    "\n",
    "    Args:\n",
    "        ret_arr (np.ndarray): The array of predicted returns.\n",
    "        params (RetToSignalParameters): Parameters for scaling and clipping the signal.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The resulting trading signal, clipped between min and max values.\n",
    "    \"\"\"\n",
    "    return np.clip(\n",
    "        ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f4bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjusted_sharpe(\n",
    "    position: np.ndarray,\n",
    "    forward_returns: np.ndarray,\n",
    "    risk_free_rate: np.ndarray,\n",
    "    min_investment: float = 0.0,\n",
    "    max_investment: float = 2.0,\n",
    "    trading_days_per_yr: int = 252\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Args:\n",
    "        position: The predicted position/signal (0 to 2).\n",
    "        forward_returns: Forward returns of the market.\n",
    "        risk_free_rate: Risk-free rate.\n",
    "        min_investment: Minimum allowed position (default 0.0).\n",
    "        max_investment: Maximum allowed position (default 2.0).\n",
    "        trading_days_per_yr: Trading days per year (default 252).\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "    # Validate position range\n",
    "    if position.max() > max_investment:\n",
    "        raise ValueError(f'Position of {position.max()} exceeds maximum of {max_investment}')\n",
    "    if position.min() < min_investment:\n",
    "        raise ValueError(f'Position of {position.min()} below minimum of {min_investment}')\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    strategy_returns = risk_free_rate * (1 - position) + position * forward_returns\n",
    "    \n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = strategy_returns - risk_free_rate\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(forward_returns)) - 1\n",
    "    strategy_std = strategy_returns.std()\n",
    "    \n",
    "    if strategy_std == 0:\n",
    "        raise ValueError('Division by zero, strategy std is zero')\n",
    "    \n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "    \n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = forward_returns - risk_free_rate\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(forward_returns)) - 1\n",
    "    market_std = forward_returns.std()\n",
    "    \n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "    \n",
    "    if market_volatility == 0:\n",
    "        raise ValueError('Division by zero, market std is zero')\n",
    "    \n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "    \n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "    \n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return min(float(adjusted_sharpe), 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe5ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preview_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m dataset = split_dataset(train, test, features)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Show full table previews\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mpreview_dataset\u001b[49m(dataset, n=\u001b[32m30\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# # Print outputs\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# print(\"==== DATASET OUTPUT ====\")\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# print(\"X_train shape:\", dataset.X_train.shape)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# print(\"\\nDataset dataclass summary:\")\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# print(dataset)\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreview_dataset\u001b[39m(dataset: DatasetOutput, n: \u001b[38;5;28mint\u001b[39m = \u001b[32m12\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'preview_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw data\n",
    "train_raw = load_trainset()\n",
    "test_raw = load_testset()\n",
    "\n",
    "# Feature engineering\n",
    "train = create_example_dataset(train_raw)\n",
    "test = create_example_dataset(test_raw)\n",
    "\n",
    "# Extract feature names\n",
    "features = [col for col in train.columns if col not in (\"date_id\", \"target\")]\n",
    "\n",
    "# Split and scale\n",
    "dataset = split_dataset(train, test, features)\n",
    "\n",
    "# Show full table previews\n",
    "preview_dataset(dataset, n=30)\n",
    "\n",
    "\n",
    "# # Print outputs\n",
    "# print(\"==== DATASET OUTPUT ====\")\n",
    "# print(\"X_train shape:\", dataset.X_train.shape)\n",
    "# print(\"X_test shape:\", dataset.X_test.shape)\n",
    "# print(\"y_train length:\", len(dataset.y_train))\n",
    "# print(\"y_test length:\", len(dataset.y_test))\n",
    "# print(\"\\nScaler mean (first 5 features):\", dataset.scaler.mean_[:100])\n",
    "# print(\"\\nDataset dataclass summary:\")\n",
    "# print(dataset)\n",
    "\n",
    "def preview_dataset(dataset: DatasetOutput, n: int = 12) -> None:\n",
    "    print(\"=== TRAIN FEATURES (X_train) ===\")\n",
    "    display(dataset.X_train.to_pandas().head(n))\n",
    "    print(\"\\n\")\n",
    "    print(\"=== TRAIN TARGET (y_train length) ===\")\n",
    "    display(pd.DataFrame(dataset.y_train.to_numpy(), columns=[\"target\"]).head(n))\n",
    "\n",
    "def preview_dataset(dataset: DatasetOutput, n: int = 12) -> None:\n",
    "    print(\"=== TEST FEATURES (X_test) ===\")\n",
    "    display(dataset.X_test.to_pandas().head(n))\n",
    "    print(\"\\n\")\n",
    "    print(\"=== TEST TARGET (y_test length) ===\")\n",
    "    display(pd.DataFrame(dataset.y_test.to_numpy(), columns=[\"target\"]).head(n))\n",
    "\n",
    "def preview_dataset(dataset: DatasetOutput, n: int = 12) -> None:\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n=== SCALER SUMMARY ===\")\n",
    "    print(\"Mean (first 5):\", dataset.scaler.mean_[:5])\n",
    "    print(\"Scale (first 5):\", dataset.scaler.scale_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82941f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN FEATURES (X_train) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S2</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>P9</th>\n",
       "      <th>S1</th>\n",
       "      <th>S5</th>\n",
       "      <th>I2</th>\n",
       "      <th>P8</th>\n",
       "      <th>P10</th>\n",
       "      <th>P12</th>\n",
       "      <th>P13</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.285955</td>\n",
       "      <td>1.112088</td>\n",
       "      <td>1.674268</td>\n",
       "      <td>1.627662</td>\n",
       "      <td>0.166740</td>\n",
       "      <td>-0.129887</td>\n",
       "      <td>-0.821713</td>\n",
       "      <td>0.276656</td>\n",
       "      <td>0.635604</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>0.309654</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>-0.016005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.395515</td>\n",
       "      <td>1.123292</td>\n",
       "      <td>1.686506</td>\n",
       "      <td>1.629398</td>\n",
       "      <td>0.159627</td>\n",
       "      <td>-0.041275</td>\n",
       "      <td>-0.811496</td>\n",
       "      <td>0.305054</td>\n",
       "      <td>0.646199</td>\n",
       "      <td>-0.516780</td>\n",
       "      <td>0.308522</td>\n",
       "      <td>-0.794458</td>\n",
       "      <td>-0.014148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045640</td>\n",
       "      <td>1.144137</td>\n",
       "      <td>1.710228</td>\n",
       "      <td>1.631135</td>\n",
       "      <td>0.159589</td>\n",
       "      <td>-0.033100</td>\n",
       "      <td>-0.851134</td>\n",
       "      <td>0.312833</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>-0.700966</td>\n",
       "      <td>0.307390</td>\n",
       "      <td>-0.842952</td>\n",
       "      <td>-0.014439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.817345</td>\n",
       "      <td>1.141328</td>\n",
       "      <td>1.705303</td>\n",
       "      <td>1.632871</td>\n",
       "      <td>0.147790</td>\n",
       "      <td>-0.411799</td>\n",
       "      <td>-0.865743</td>\n",
       "      <td>0.306904</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>-0.515000</td>\n",
       "      <td>0.306258</td>\n",
       "      <td>-0.853212</td>\n",
       "      <td>-0.015070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.597401</td>\n",
       "      <td>1.131427</td>\n",
       "      <td>1.691863</td>\n",
       "      <td>1.634607</td>\n",
       "      <td>0.128952</td>\n",
       "      <td>-0.139996</td>\n",
       "      <td>-0.888585</td>\n",
       "      <td>0.303112</td>\n",
       "      <td>0.643282</td>\n",
       "      <td>-0.514195</td>\n",
       "      <td>0.305126</td>\n",
       "      <td>-0.872823</td>\n",
       "      <td>-0.014420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.487707</td>\n",
       "      <td>1.146221</td>\n",
       "      <td>1.708103</td>\n",
       "      <td>1.636344</td>\n",
       "      <td>0.114871</td>\n",
       "      <td>-0.064001</td>\n",
       "      <td>-0.911353</td>\n",
       "      <td>0.303532</td>\n",
       "      <td>0.647676</td>\n",
       "      <td>0.791638</td>\n",
       "      <td>0.303993</td>\n",
       "      <td>-0.900752</td>\n",
       "      <td>-0.014758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.818884</td>\n",
       "      <td>1.194114</td>\n",
       "      <td>1.763710</td>\n",
       "      <td>1.638080</td>\n",
       "      <td>0.100811</td>\n",
       "      <td>0.031098</td>\n",
       "      <td>-0.934034</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.682545</td>\n",
       "      <td>0.412286</td>\n",
       "      <td>0.302861</td>\n",
       "      <td>-0.930325</td>\n",
       "      <td>-0.013438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.818492</td>\n",
       "      <td>1.195059</td>\n",
       "      <td>1.763027</td>\n",
       "      <td>1.639816</td>\n",
       "      <td>0.079709</td>\n",
       "      <td>-0.288987</td>\n",
       "      <td>-0.931795</td>\n",
       "      <td>0.322269</td>\n",
       "      <td>0.685368</td>\n",
       "      <td>-0.142893</td>\n",
       "      <td>0.301729</td>\n",
       "      <td>-0.925471</td>\n",
       "      <td>-0.013006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.038009</td>\n",
       "      <td>1.149421</td>\n",
       "      <td>1.706920</td>\n",
       "      <td>1.641553</td>\n",
       "      <td>0.079824</td>\n",
       "      <td>-0.160765</td>\n",
       "      <td>-0.937840</td>\n",
       "      <td>0.305796</td>\n",
       "      <td>0.654090</td>\n",
       "      <td>-0.697855</td>\n",
       "      <td>0.300597</td>\n",
       "      <td>-0.934209</td>\n",
       "      <td>-0.013037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.486466</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>1.686006</td>\n",
       "      <td>1.643289</td>\n",
       "      <td>0.065811</td>\n",
       "      <td>0.104361</td>\n",
       "      <td>-0.877735</td>\n",
       "      <td>0.306325</td>\n",
       "      <td>0.652019</td>\n",
       "      <td>-0.141291</td>\n",
       "      <td>0.299464</td>\n",
       "      <td>-0.881453</td>\n",
       "      <td>-0.013886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         S2        E2        E3        P9        S1        S5        I2  \\\n",
       "0 -0.285955  1.112088  1.674268  1.627662  0.166740 -0.129887 -0.821713   \n",
       "1 -0.395515  1.123292  1.686506  1.629398  0.159627 -0.041275 -0.811496   \n",
       "2  0.045640  1.144137  1.710228  1.631135  0.159589 -0.033100 -0.851134   \n",
       "3  0.817345  1.141328  1.705303  1.632871  0.147790 -0.411799 -0.865743   \n",
       "4  0.597401  1.131427  1.691863  1.634607  0.128952 -0.139996 -0.888585   \n",
       "5  0.487707  1.146221  1.708103  1.636344  0.114871 -0.064001 -0.911353   \n",
       "6  0.818884  1.194114  1.763710  1.638080  0.100811  0.031098 -0.934034   \n",
       "7  0.818492  1.195059  1.763027  1.639816  0.079709 -0.288987 -0.931795   \n",
       "8  1.038009  1.149421  1.706920  1.641553  0.079824 -0.160765 -0.937840   \n",
       "9  0.486466  1.133204  1.686006  1.643289  0.065811  0.104361 -0.877735   \n",
       "\n",
       "         P8       P10       P12       P13        U1        U2  \n",
       "0  0.276656  0.635604 -0.138087  0.309654 -0.803976 -0.016005  \n",
       "1  0.305054  0.646199 -0.516780  0.308522 -0.794458 -0.014148  \n",
       "2  0.312833  0.661098 -0.700966  0.307390 -0.842952 -0.014439  \n",
       "3  0.306904  0.651978 -0.515000  0.306258 -0.853212 -0.015070  \n",
       "4  0.303112  0.643282 -0.514195  0.305126 -0.872823 -0.014420  \n",
       "5  0.303532  0.647676  0.791638  0.303993 -0.900752 -0.014758  \n",
       "6  0.320816  0.682545  0.412286  0.302861 -0.930325 -0.013438  \n",
       "7  0.322269  0.685368 -0.142893  0.301729 -0.925471 -0.013006  \n",
       "8  0.305796  0.654090 -0.697855  0.300597 -0.934209 -0.013037  \n",
       "9  0.306325  0.652019 -0.141291  0.299464 -0.881453 -0.013886  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST FEATURES (X_test) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S2</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>P9</th>\n",
       "      <th>S1</th>\n",
       "      <th>S5</th>\n",
       "      <th>I2</th>\n",
       "      <th>P8</th>\n",
       "      <th>P10</th>\n",
       "      <th>P12</th>\n",
       "      <th>P13</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071202</td>\n",
       "      <td>0.577252</td>\n",
       "      <td>0.979946</td>\n",
       "      <td>-0.884859</td>\n",
       "      <td>0.082628</td>\n",
       "      <td>-0.124857</td>\n",
       "      <td>1.193316</td>\n",
       "      <td>0.343976</td>\n",
       "      <td>0.791547</td>\n",
       "      <td>0.813018</td>\n",
       "      <td>1.002565</td>\n",
       "      <td>1.462864</td>\n",
       "      <td>-0.014660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259606</td>\n",
       "      <td>0.531720</td>\n",
       "      <td>0.931516</td>\n",
       "      <td>-0.874441</td>\n",
       "      <td>0.089617</td>\n",
       "      <td>0.052103</td>\n",
       "      <td>1.165067</td>\n",
       "      <td>0.324842</td>\n",
       "      <td>0.762751</td>\n",
       "      <td>-0.379850</td>\n",
       "      <td>0.717249</td>\n",
       "      <td>1.436112</td>\n",
       "      <td>-0.014608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.321790</td>\n",
       "      <td>0.483057</td>\n",
       "      <td>0.879877</td>\n",
       "      <td>-0.877914</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>0.227982</td>\n",
       "      <td>1.204837</td>\n",
       "      <td>0.302967</td>\n",
       "      <td>0.736316</td>\n",
       "      <td>0.345253</td>\n",
       "      <td>-0.990119</td>\n",
       "      <td>1.484485</td>\n",
       "      <td>-0.014716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.058333</td>\n",
       "      <td>0.514029</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>-0.874441</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.090467</td>\n",
       "      <td>1.244544</td>\n",
       "      <td>0.324163</td>\n",
       "      <td>0.750651</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>0.544021</td>\n",
       "      <td>1.540940</td>\n",
       "      <td>-0.014149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186197</td>\n",
       "      <td>0.566596</td>\n",
       "      <td>0.967275</td>\n",
       "      <td>-0.858814</td>\n",
       "      <td>0.036628</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>1.182242</td>\n",
       "      <td>0.345811</td>\n",
       "      <td>0.772634</td>\n",
       "      <td>0.598144</td>\n",
       "      <td>-0.599508</td>\n",
       "      <td>1.486083</td>\n",
       "      <td>-0.014469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.440632</td>\n",
       "      <td>0.542675</td>\n",
       "      <td>0.941613</td>\n",
       "      <td>-0.858814</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>1.160807</td>\n",
       "      <td>0.345010</td>\n",
       "      <td>0.760766</td>\n",
       "      <td>0.599486</td>\n",
       "      <td>0.422875</td>\n",
       "      <td>1.455728</td>\n",
       "      <td>-0.014867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.124694</td>\n",
       "      <td>0.553926</td>\n",
       "      <td>0.953023</td>\n",
       "      <td>-0.865759</td>\n",
       "      <td>0.085354</td>\n",
       "      <td>0.063544</td>\n",
       "      <td>1.098616</td>\n",
       "      <td>0.354122</td>\n",
       "      <td>0.765722</td>\n",
       "      <td>0.844027</td>\n",
       "      <td>0.813486</td>\n",
       "      <td>1.399496</td>\n",
       "      <td>-0.014670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.315846</td>\n",
       "      <td>0.569067</td>\n",
       "      <td>0.968520</td>\n",
       "      <td>-0.855341</td>\n",
       "      <td>0.137411</td>\n",
       "      <td>-0.057029</td>\n",
       "      <td>1.050089</td>\n",
       "      <td>0.355790</td>\n",
       "      <td>0.766012</td>\n",
       "      <td>-0.629474</td>\n",
       "      <td>1.052382</td>\n",
       "      <td>1.350650</td>\n",
       "      <td>-0.014263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.316883</td>\n",
       "      <td>0.586179</td>\n",
       "      <td>0.986030</td>\n",
       "      <td>-0.839714</td>\n",
       "      <td>0.166180</td>\n",
       "      <td>-0.032250</td>\n",
       "      <td>1.062804</td>\n",
       "      <td>0.355952</td>\n",
       "      <td>0.769013</td>\n",
       "      <td>1.335549</td>\n",
       "      <td>1.444125</td>\n",
       "      <td>1.363049</td>\n",
       "      <td>-0.014080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000524</td>\n",
       "      <td>0.614430</td>\n",
       "      <td>1.015162</td>\n",
       "      <td>-0.837977</td>\n",
       "      <td>0.165597</td>\n",
       "      <td>-0.123211</td>\n",
       "      <td>1.034709</td>\n",
       "      <td>0.360814</td>\n",
       "      <td>0.789748</td>\n",
       "      <td>0.352787</td>\n",
       "      <td>1.316186</td>\n",
       "      <td>1.311524</td>\n",
       "      <td>-0.013962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         S2        E2        E3        P9        S1        S5        I2  \\\n",
       "0  0.071202  0.577252  0.979946 -0.884859  0.082628 -0.124857  1.193316   \n",
       "1  0.259606  0.531720  0.931516 -0.874441  0.089617  0.052103  1.165067   \n",
       "2  0.321790  0.483057  0.879877 -0.877914  0.056102  0.227982  1.204837   \n",
       "3 -0.058333  0.514029  0.912258 -0.874441  0.016603  0.090467  1.244544   \n",
       "4 -0.186197  0.566596  0.967275 -0.858814  0.036628 -0.021156  1.182242   \n",
       "5 -0.440632  0.542675  0.941613 -0.858814  0.050615  0.017770  1.160807   \n",
       "6 -0.124694  0.553926  0.953023 -0.865759  0.085354  0.063544  1.098616   \n",
       "7 -0.315846  0.569067  0.968520 -0.855341  0.137411 -0.057029  1.050089   \n",
       "8 -0.316883  0.586179  0.986030 -0.839714  0.166180 -0.032250  1.062804   \n",
       "9 -0.000524  0.614430  1.015162 -0.837977  0.165597 -0.123211  1.034709   \n",
       "\n",
       "         P8       P10       P12       P13        U1        U2  \n",
       "0  0.343976  0.791547  0.813018  1.002565  1.462864 -0.014660  \n",
       "1  0.324842  0.762751 -0.379850  0.717249  1.436112 -0.014608  \n",
       "2  0.302967  0.736316  0.345253 -0.990119  1.484485 -0.014716  \n",
       "3  0.324163  0.750651  0.345485  0.544021  1.540940 -0.014149  \n",
       "4  0.345811  0.772634  0.598144 -0.599508  1.486083 -0.014469  \n",
       "5  0.345010  0.760766  0.599486  0.422875  1.455728 -0.014867  \n",
       "6  0.354122  0.765722  0.844027  0.813486  1.399496 -0.014670  \n",
       "7  0.355790  0.766012 -0.629474  1.052382  1.350650 -0.014263  \n",
       "8  0.355952  0.769013  1.335549  1.444125  1.363049 -0.014080  \n",
       "9  0.360814  0.789748  0.352787  1.316186  1.311524 -0.013962  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN TARGET (y_train) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.010042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0  0.003079\n",
       "1  0.004344\n",
       "2 -0.001013\n",
       "3 -0.001524\n",
       "4  0.000767\n",
       "5  0.010164\n",
       "6  0.002256\n",
       "7 -0.010042\n",
       "8 -0.002539\n",
       "9  0.003291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST TARGET (y_test) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0  0.003541\n",
       "1 -0.005964\n",
       "2 -0.007410\n",
       "3  0.005420\n",
       "4  0.008357\n",
       "5 -0.002896\n",
       "6  0.002457\n",
       "7  0.002312\n",
       "8  0.002891\n",
       "9  0.008310"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SCALER SUMMARY ===\n",
      "Mean (first 5): [0.01165369 0.42743324 0.24506963 0.36680174 0.179122  ]\n",
      "Scale (first 5): [1.04017828 1.44067354 1.4975419  0.38089654 1.39900821]\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare\n",
    "train_raw = load_trainset()\n",
    "test_raw = load_testset()\n",
    "\n",
    "train = create_example_dataset(train_raw)\n",
    "test = create_example_dataset(test_raw)\n",
    "\n",
    "# Define features\n",
    "features = [col for col in train.columns if col not in (\"date_id\", \"target\")]\n",
    "\n",
    "# Split\n",
    "dataset = split_dataset(train, test, features)\n",
    "\n",
    "# Show full table previews\n",
    "preview_dataset(dataset, n=10)\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your earlier dataclasses and functions (DatasetOutput, load_trainset, etc.) are already defined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6d074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the Hull Tactical Market Prediction model.\"\"\"\n",
    "    print(\"Starting Hull Tactical Market Prediction...\")\n",
    "    \n",
    "    # Looking at the Data\n",
    "    train: pl.DataFrame = load_trainset()\n",
    "    test: pl.DataFrame = load_testset() \n",
    "    print(\"Training data shape:\", train.shape)\n",
    "    print(\"Test data shape:\", test.shape)\n",
    "    print(train.tail(3)) \n",
    "    print(test.head(3))\n",
    "\n",
    "    # Store financial columns from training data before joining\n",
    "    train_financial = train.select(['date_id', 'forward_returns', 'risk_free_rate'])\n",
    "    \n",
    "    # Generating the Train and Test\n",
    "    df: pl.DataFrame = join_train_test_dataframes(train, test)\n",
    "    df = create_example_dataset(df=df) \n",
    "    train_date_ids = train.get_column('date_id')\n",
    "    test_date_ids = test.get_column('date_id')\n",
    "    train: pl.DataFrame = df.filter(pl.col('date_id').is_in(train_date_ids.to_list()))\n",
    "    test: pl.DataFrame = df.filter(pl.col('date_id').is_in(test_date_ids.to_list()))\n",
    "    \n",
    "    # Join financial columns back to train\n",
    "    train = train.join(train_financial, on='date_id', how='left')\n",
    "\n",
    "    # Exclude financial columns from features to avoid data leakage\n",
    "    excluded_cols = ['date_id', 'target', 'forward_returns', 'risk_free_rate']\n",
    "    FEATURES: list[str] = [col for col in test.columns if col not in excluded_cols]\n",
    "    print(f\"Features used: {FEATURES}\")\n",
    "\n",
    "    dataset: DatasetOutput = split_dataset(train=train, test=test, features=FEATURES) \n",
    "\n",
    "    X_train: pl.DataFrame = dataset.X_train\n",
    "    X_test: pl.DataFrame = dataset.X_test\n",
    "    y_train: pl.Series = dataset.y_train\n",
    "    y_test: pl.Series = dataset.y_test\n",
    "    scaler: StandardScaler = dataset.scaler \n",
    "\n",
    "    # Fitting the Model\n",
    "    print(\"Fitting ElasticNet model with cross-validation...\")\n",
    "    model_cv: ElasticNetCV = ElasticNetCV(\n",
    "        **asdict(enet_params)\n",
    "    )\n",
    "    model_cv.fit(X_train, y_train) \n",
    "            \n",
    "    # Fit the final model using the best alpha found by cross-validation\n",
    "    model: ElasticNet = ElasticNet(alpha=model_cv.alpha_, l1_ratio=enet_params.l1_ratio) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best alpha found: {model_cv.alpha_}\")\n",
    "    print(f\"Model coefficients: {model.coef_}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    signals = convert_ret_to_signal(predictions, ret_signal_params)\n",
    "    \n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "    print(f\"Signals shape: {signals.shape}\")\n",
    "    print(f\"Signal range: [{signals.min():.4f}, {signals.max():.4f}]\")\n",
    "    \n",
    "    # Calculate the adjusted Sharpe ratio score on training data (validation)\n",
    "    if 'forward_returns' in train.columns and 'risk_free_rate' in train.columns:\n",
    "        # Use the last portion of training data as validation\n",
    "        val_size = min(1000, len(train))\n",
    "        val_train = train.tail(val_size)\n",
    "        val_X = val_train.select(FEATURES)\n",
    "        val_X_scaled_np = scaler.transform(val_X)\n",
    "        val_X_scaled = pl.from_numpy(val_X_scaled_np, schema=FEATURES)\n",
    "        \n",
    "        val_predictions = model.predict(val_X_scaled)\n",
    "        val_signals = convert_ret_to_signal(val_predictions, ret_signal_params)\n",
    "        \n",
    "        forward_returns = val_train.get_column('forward_returns').to_numpy()\n",
    "        risk_free_rate = val_train.get_column('risk_free_rate').to_numpy()\n",
    "        \n",
    "        try:\n",
    "            adjusted_sharpe = calculate_adjusted_sharpe(\n",
    "                position=val_signals,\n",
    "                forward_returns=forward_returns,\n",
    "                risk_free_rate=risk_free_rate\n",
    "            )\n",
    "            print(f\"\\nValidation Adjusted Sharpe Ratio: {adjusted_sharpe:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError calculating validation score: {e}\")\n",
    "    \n",
    "    return model, predictions, signals, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ba0bd",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "211ef9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hull Tactical Market Prediction...\n",
      "Training data shape: (8980, 98)\n",
      "Test data shape: (10, 99)\n",
      "shape: (3, 98)\n",
      "\n",
      " date_id  D1   D2   D3     V9         forward_returns  risk_free_rate  target   \n",
      " ---      ---  ---  ---     ---        ---              ---             ---      \n",
      " i64      f64  f64  f64     f64        f64              f64             f64      \n",
      "\n",
      " 8977     0.0  0.0  0.0    -0.708599  0.004187         0.000162        0.003713 \n",
      " 8978     0.0  0.0  0.0    -0.725858  0.002279         0.000162        0.001805 \n",
      " 8979     0.0  0.0  0.0    -0.720092  0.003541         0.000161        0.003068 \n",
      "\n",
      "shape: (3, 99)\n",
      "\n",
      " date_id  D1   D2   D3     is_scored  target     lagged_risk_free_ra  lagged_market_forw \n",
      " ---      ---  ---  ---     ---        ---        te                   ard_excess_r      \n",
      " i64      f64  f64  f64     f64        f64        ---                  ---                \n",
      "                                                  f64                  f64                \n",
      "\n",
      " 8980     0.0  0.0  0.0    1.0        0.003541   0.000161             0.003068           \n",
      " 8981     0.0  0.0  0.0    1.0        -0.005964  0.000162             -0.006437          \n",
      " 8982     0.0  0.0  0.0    1.0        -0.00741   0.00016              -0.007882          \n",
      "\n",
      "Features used: ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13']\n",
      "Fitting ElasticNet model with cross-validation...\n",
      "Best alpha found: 0.0014174741629268048\n",
      "Model coefficients: [ 0.          0.         -0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.         -0.\n",
      "  0.          0.         -0.         -0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      " -0.         -0.         -0.          0.         -0.          0.\n",
      " -0.          0.         -0.         -0.         -0.          0.\n",
      "  0.         -0.          0.          0.          0.         -0.\n",
      " -0.          0.          0.         -0.          0.         -0.\n",
      " -0.         -0.          0.          0.         -0.         -0.\n",
      "  0.         -0.          0.          0.         -0.          0.\n",
      " -0.         -0.         -0.         -0.          0.         -0.00016555\n",
      " -0.         -0.         -0.          0.         -0.          0.\n",
      "  0.          0.          0.         -0.         -0.         -0.\n",
      "  0.          0.         -0.         -0.          0.         -0.\n",
      "  0.          0.         -0.          0.         -0.          0.\n",
      "  0.         -0.         -0.          0.        ]\n",
      "Predictions shape: (10,)\n",
      "Signals shape: (10,)\n",
      "Signal range: [1.0445, 1.0521]\n",
      "\n",
      "Validation Adjusted Sharpe Ratio: 0.3598\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, predictions, signals, test_data = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
